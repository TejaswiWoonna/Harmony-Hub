{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933912af-8c71-451c-ad11-9fde9c1db6df",
   "metadata": {},
   "source": [
    "### Data Preprocessing with target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15bcda8-7229-4a96-8a0e-5aaa46e9b706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing training data...\n",
      "\n",
      "Processing training data from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData\n",
      "Found 10 instrument folders: piano, cello, violin, electric guitar , clarinet, organ, flute , trumpet , acoustic guitar, saxophone\n",
      "\n",
      "Processing piano files from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData/piano\n",
      "Found 52 files for piano\n",
      "Processed 10 files...\n",
      "Processed 20 files...\n",
      "Processed 30 files...\n",
      "Processed 40 files...\n",
      "Processed 50 files...\n",
      "\n",
      "Processing cello files from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData/cello\n",
      "Found 49 files for cello\n",
      "Processed 60 files...\n",
      "Processed 70 files...\n",
      "Processed 80 files...\n",
      "Processed 90 files...\n",
      "Processed 100 files...\n",
      "\n",
      "Processing violin files from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData/violin\n",
      "Found 49 files for violin\n",
      "Processed 110 files...\n",
      "Processed 120 files...\n",
      "Processed 130 files...\n",
      "Processed 140 files...\n",
      "Processed 150 files...\n",
      "\n",
      "Processing electric guitar  files from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData/electric guitar \n",
      "Found 49 files for electric guitar \n",
      "Processed 160 files...\n",
      "Processed 170 files...\n",
      "Processed 180 files...\n",
      "Processed 190 files...\n",
      "\n",
      "Processing clarinet files from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData/clarinet\n",
      "Found 49 files for clarinet\n",
      "Processed 200 files...\n",
      "Processed 210 files...\n",
      "Processed 220 files...\n",
      "Processed 230 files...\n",
      "Processed 240 files...\n",
      "\n",
      "Processing organ files from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData/organ\n",
      "Found 49 files for organ\n",
      "Processed 250 files...\n",
      "Processed 260 files...\n",
      "Processed 270 files...\n",
      "Processed 280 files...\n",
      "Processed 290 files...\n",
      "\n",
      "Processing flute  files from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData/flute \n",
      "Found 49 files for flute \n",
      "Processed 300 files...\n",
      "Processed 310 files...\n",
      "Processed 320 files...\n",
      "Processed 330 files...\n",
      "Processed 340 files...\n",
      "\n",
      "Processing trumpet  files from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData/trumpet \n",
      "Found 49 files for trumpet \n",
      "Processed 350 files...\n",
      "Processed 360 files...\n",
      "Processed 370 files...\n",
      "Processed 380 files...\n",
      "Processed 390 files...\n",
      "\n",
      "Processing acoustic guitar files from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData/acoustic guitar\n",
      "Found 49 files for acoustic guitar\n",
      "Processed 400 files...\n",
      "Processed 410 files...\n",
      "Processed 420 files...\n",
      "Processed 430 files...\n",
      "Processed 440 files...\n",
      "\n",
      "Processing saxophone files from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData/saxophone\n",
      "Found 49 files for saxophone\n",
      "Processed 450 files...\n",
      "Processed 460 files...\n",
      "Processed 470 files...\n",
      "Processed 480 files...\n",
      "Processed 490 files...\n",
      "\n",
      "Processing complete. Successfully processed 493 files. Failed: 0\n",
      "Training data shape: (493, 33)\n",
      "\n",
      "Processing testing data...\n",
      "\n",
      "Processing testing data from: /Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TestingData\n",
      "Found 300 test files\n",
      "Processed 10 files...\n",
      "Processed 20 files...\n",
      "Processed 30 files...\n",
      "Processed 40 files...\n",
      "Processed 50 files...\n",
      "Processed 60 files...\n",
      "Processed 70 files...\n",
      "Processed 80 files...\n",
      "Processed 90 files...\n",
      "Processed 100 files...\n",
      "Processed 110 files...\n",
      "Processed 120 files...\n",
      "Processed 130 files...\n",
      "Processed 140 files...\n",
      "Processed 150 files...\n",
      "Processed 160 files...\n",
      "Processed 170 files...\n",
      "Processed 180 files...\n",
      "Processed 190 files...\n",
      "Processed 200 files...\n",
      "Processed 210 files...\n",
      "Processed 220 files...\n",
      "Processed 230 files...\n",
      "Processed 240 files...\n",
      "Processed 250 files...\n",
      "Processed 260 files...\n",
      "Processed 270 files...\n",
      "Processed 280 files...\n",
      "Processed 290 files...\n",
      "Processed 300 files...\n",
      "\n",
      "Processing complete. Successfully processed 300 files. Failed: 0\n",
      "Testing data shape: (300, 33)\n",
      "\n",
      "Normalizing features...\n",
      "\n",
      "Dataset processing complete!\n",
      "\n",
      "Feature statistics (training data):\n",
      "       spectral_centroid_mean  spectral_bandwidth_mean  spectral_rolloff_mean  \\\n",
      "count            4.930000e+02             4.930000e+02           4.930000e+02   \n",
      "mean             4.323789e-16            -6.053305e-16          -8.647579e-17   \n",
      "std              1.001016e+00             1.001016e+00           1.001016e+00   \n",
      "min             -1.940013e+00            -2.290157e+00          -1.970939e+00   \n",
      "25%             -8.131367e-01            -8.154170e-01          -7.949089e-01   \n",
      "50%              2.609512e-03             9.583824e-02          -6.413549e-02   \n",
      "75%              7.436528e-01             8.417133e-01           7.789754e-01   \n",
      "max              2.963200e+00             2.300978e+00           2.839533e+00   \n",
      "\n",
      "              tempo  zero_crossing_rate     rmse_mean   mfcc_1_mean  \\\n",
      "count  4.930000e+02        4.930000e+02  4.930000e+02  4.930000e+02   \n",
      "mean  -1.369200e-16       -3.603158e-17 -1.441263e-17 -1.153011e-16   \n",
      "std    1.001016e+00        1.001016e+00  1.001016e+00  1.001016e+00   \n",
      "min   -2.846216e+00       -1.706722e+00 -1.234830e+00 -3.314284e+00   \n",
      "25%   -6.494968e-01       -7.684854e-01 -8.612463e-01 -7.547929e-01   \n",
      "50%   -1.277760e-01       -1.373101e-01 -2.341475e-01  9.023475e-02   \n",
      "75%    5.098828e-01        5.362330e-01  6.266859e-01  7.878547e-01   \n",
      "max    3.698177e+00        3.273303e+00  3.411250e+00  1.977610e+00   \n",
      "\n",
      "        mfcc_2_mean  mfcc_3_mean   mfcc_4_mean  ...  chroma_3_mean  \\\n",
      "count  4.930000e+02   493.000000  4.930000e+02  ...     493.000000   \n",
      "mean   8.647579e-17     0.000000  6.846000e-17  ...       0.000000   \n",
      "std    1.001016e+00     1.001016  1.001016e+00  ...       1.001016   \n",
      "min   -2.359509e+00    -3.434233 -4.466324e+00  ...      -1.711948   \n",
      "25%   -7.622726e-01    -0.697106 -5.010955e-01  ...      -0.716130   \n",
      "50%   -1.464073e-01    -0.002326  2.750580e-02  ...      -0.146564   \n",
      "75%    6.954360e-01     0.723603  6.125757e-01  ...       0.557366   \n",
      "max    2.918763e+00     3.083554  2.756170e+00  ...       3.484695   \n",
      "\n",
      "       chroma_4_mean  chroma_5_mean  chroma_6_mean  chroma_7_mean  \\\n",
      "count   4.930000e+02   4.930000e+02   4.930000e+02   4.930000e+02   \n",
      "mean    9.368211e-17   1.297137e-16  -9.368211e-17  -4.323789e-17   \n",
      "std     1.001016e+00   1.001016e+00   1.001016e+00   1.001016e+00   \n",
      "min    -1.697096e+00  -1.579578e+00  -1.619688e+00  -1.667731e+00   \n",
      "25%    -6.863310e-01  -7.709544e-01  -7.439763e-01  -7.746190e-01   \n",
      "50%    -1.171575e-01  -1.759638e-01  -2.161481e-01  -1.347187e-01   \n",
      "75%     4.486089e-01   5.075303e-01   5.664905e-01   6.318491e-01   \n",
      "max     4.330225e+00   3.271724e+00   3.865489e+00   3.428141e+00   \n",
      "\n",
      "       chroma_8_mean  chroma_9_mean  chroma_10_mean  chroma_11_mean  \\\n",
      "count   4.930000e+02   4.930000e+02    4.930000e+02    4.930000e+02   \n",
      "mean    1.441263e-17  -5.584895e-17   -1.441263e-17   -7.926947e-17   \n",
      "std     1.001016e+00   1.001016e+00    1.001016e+00    1.001016e+00   \n",
      "min    -1.575882e+00  -1.568655e+00   -1.759372e+00   -1.549112e+00   \n",
      "25%    -7.152812e-01  -7.252364e-01   -7.458543e-01   -7.256123e-01   \n",
      "50%    -1.363958e-01  -1.067394e-01   -1.594409e-01   -1.831481e-01   \n",
      "75%     5.127824e-01   5.592256e-01    6.205883e-01    4.849879e-01   \n",
      "max     3.782222e+00   4.366563e+00    3.504023e+00    4.196191e+00   \n",
      "\n",
      "       chroma_12_mean  \n",
      "count    4.930000e+02  \n",
      "mean     5.765053e-17  \n",
      "std      1.001016e+00  \n",
      "min     -1.612578e+00  \n",
      "25%     -7.171403e-01  \n",
      "50%     -1.956298e-01  \n",
      "75%      4.695218e-01  \n",
      "max      4.130739e+00  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "\n",
      "Instrument distribution in training data:\n",
      "instrument_type\n",
      "piano               52\n",
      "cello               49\n",
      "violin              49\n",
      "electric guitar     49\n",
      "clarinet            49\n",
      "organ               49\n",
      "flute               49\n",
      "trumpet             49\n",
      "acoustic guitar     49\n",
      "saxophone           49\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MusicPreprocessor:\n",
    "    def __init__(self, sample_rate=22050, duration=5):\n",
    "        \"\"\"\n",
    "        Initialize the music preprocessor\n",
    "        \n",
    "        Args:\n",
    "            sample_rate (int): Sample rate for audio processing\n",
    "            duration (int): Duration in seconds to analyze\n",
    "        \"\"\"\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration = duration\n",
    "        self.n_mfcc = 13\n",
    "        self.n_fft = 2048\n",
    "        self.hop_length = 512\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def extract_mfcc_features(self, y, sr):\n",
    "        \"\"\"\n",
    "        Extract detailed MFCC features from audio signal\n",
    "        \n",
    "        Args:\n",
    "            y (np.array): Audio time series\n",
    "            sr (int): Sampling rate\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing MFCC features\n",
    "        \"\"\"\n",
    "        # Extract MFCCs\n",
    "        mfccs = librosa.feature.mfcc(\n",
    "            y=y, \n",
    "            sr=sr,\n",
    "            n_mfcc=self.n_mfcc,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length\n",
    "        )\n",
    "        \n",
    "        # Calculate statistics for each MFCC coefficient\n",
    "        mfcc_features = {}\n",
    "        \n",
    "        for i in range(self.n_mfcc):\n",
    "            mfcc_features.update({\n",
    "                f'mfcc_{i+1}_mean': np.mean(mfccs[i]),\n",
    "                f'mfcc_{i+1}_std': np.std(mfccs[i]),\n",
    "                f'mfcc_{i+1}_max': np.max(mfccs[i]),\n",
    "                f'mfcc_{i+1}_min': np.min(mfccs[i]),\n",
    "                f'mfcc_{i+1}_median': np.median(mfccs[i]),\n",
    "            })\n",
    "        \n",
    "        # Calculate delta (first derivative) of MFCC\n",
    "        mfcc_delta = librosa.feature.delta(mfccs)\n",
    "        for i in range(self.n_mfcc):\n",
    "            mfcc_features.update({\n",
    "                f'mfcc_delta_{i+1}_mean': np.mean(mfcc_delta[i]),\n",
    "                f'mfcc_delta_{i+1}_std': np.std(mfcc_delta[i])\n",
    "            })\n",
    "        \n",
    "        # Calculate delta delta (second derivative) of MFCC\n",
    "        mfcc_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "        for i in range(self.n_mfcc):\n",
    "            mfcc_features.update({\n",
    "                f'mfcc_delta2_{i+1}_mean': np.mean(mfcc_delta2[i]),\n",
    "                f'mfcc_delta2_{i+1}_std': np.std(mfcc_delta2[i])\n",
    "            })\n",
    "            \n",
    "        return mfcc_features\n",
    "        \n",
    "    def process_audio(self, file_path, instrument_type):\n",
    "        \"\"\"\n",
    "        Process a single audio file and extract features\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to audio file\n",
    "            instrument_type (str): Instrument type label\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing extracted features\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check if file exists\n",
    "            if not os.path.exists(file_path):\n",
    "                raise FileNotFoundError(f\"Audio file not found: {file_path}\")\n",
    "                \n",
    "            # Load audio file with error handling\n",
    "            try:\n",
    "                y, sr = librosa.load(file_path, sr=self.sample_rate, duration=self.duration)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error loading audio file {file_path}: {str(e)}\")\n",
    "            \n",
    "            # Ensure consistent length\n",
    "            if len(y) < self.sample_rate * self.duration:\n",
    "                y = np.pad(y, (0, self.sample_rate * self.duration - len(y)))\n",
    "            else:\n",
    "                y = y[:self.sample_rate * self.duration]\n",
    "            \n",
    "            # Extract features with error handling\n",
    "            try:\n",
    "                features = {\n",
    "                    'file_name': os.path.basename(file_path),\n",
    "                    'instrument_type': instrument_type,\n",
    "                    \n",
    "                    # Spectral features\n",
    "                    'spectral_centroid_mean': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)[0]),\n",
    "                    'spectral_bandwidth_mean': np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]),\n",
    "                    'spectral_rolloff_mean': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)[0]),\n",
    "                    \n",
    "                    # Rhythm features\n",
    "                    'tempo': librosa.beat.tempo(y=y, sr=sr)[0],\n",
    "                    'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(y)[0]),\n",
    "                    \n",
    "                    # Root Mean Square Energy\n",
    "                    'rmse_mean': np.mean(librosa.feature.rms(y=y)[0]),\n",
    "                }\n",
    "                \n",
    "                # Add MFCCs\n",
    "                mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)\n",
    "                for i, mfcc in enumerate(mfccs):\n",
    "                    features[f'mfcc_{i+1}_mean'] = np.mean(mfcc)\n",
    "                \n",
    "                # Add Chromagram\n",
    "                chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "                for i, chr_feat in enumerate(chroma):\n",
    "                    features[f'chroma_{i+1}_mean'] = np.mean(chr_feat)\n",
    "                \n",
    "                return features\n",
    "                \n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error extracting features from {file_path}: {str(e)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def process_training_data(self, folder_path, verbose=True):\n",
    "        \"\"\"\n",
    "        Process training data with instrument subfolder structure\n",
    "        \n",
    "        Args:\n",
    "            folder_path (str): Path to training folder containing instrument subfolders\n",
    "            verbose (bool): Whether to print processing details\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame containing features for all audio files\n",
    "        \"\"\"\n",
    "        features_list = []\n",
    "        processed_files = 0\n",
    "        failed_files = 0\n",
    "        \n",
    "        # Check if folder exists\n",
    "        if not os.path.exists(folder_path):\n",
    "            raise ValueError(f\"Training folder not found: {folder_path}\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing training data from: {folder_path}\")\n",
    "            \n",
    "        # Get all instrument folders\n",
    "        instrument_folders = [f for f in os.listdir(folder_path) \n",
    "                            if os.path.isdir(os.path.join(folder_path, f))]\n",
    "        \n",
    "        if not instrument_folders:\n",
    "            raise ValueError(f\"No instrument folders found in {folder_path}\")\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"Found {len(instrument_folders)} instrument folders: {', '.join(instrument_folders)}\")\n",
    "        \n",
    "        # Process each instrument folder\n",
    "        for instrument in instrument_folders:\n",
    "            instrument_path = os.path.join(folder_path, instrument)\n",
    "            if verbose:\n",
    "                print(f\"\\nProcessing {instrument} files from: {instrument_path}\")\n",
    "            \n",
    "            # Get all wav files in the instrument folder\n",
    "            audio_files = list(Path(instrument_path).glob('*.wav'))\n",
    "            \n",
    "            if not audio_files:\n",
    "                print(f\"Warning: No .wav files found in {instrument_path}\")\n",
    "                continue\n",
    "                \n",
    "            if verbose:\n",
    "                print(f\"Found {len(audio_files)} files for {instrument}\")\n",
    "            \n",
    "            # Process each audio file\n",
    "            for audio_file in audio_files:\n",
    "                try:\n",
    "                    features = self.process_audio(str(audio_file), instrument)\n",
    "                    features_list.append(features)\n",
    "                    processed_files += 1\n",
    "                    if verbose and processed_files % 10 == 0:\n",
    "                        print(f\"Processed {processed_files} files...\")\n",
    "                except Exception as e:\n",
    "                    failed_files += 1\n",
    "                    print(f\"Error processing {audio_file}: {str(e)}\")\n",
    "        \n",
    "        if not features_list:\n",
    "            raise ValueError(f\"No files were successfully processed. Failed files: {failed_files}\")\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing complete. Successfully processed {processed_files} files. Failed: {failed_files}\")\n",
    "            \n",
    "        df = pd.DataFrame(features_list)\n",
    "        \n",
    "        # Convert all columns to float except 'file_name' and 'instrument_type'\n",
    "        for col in df.columns:\n",
    "            if col not in ['file_name', 'instrument_type']:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "        return df\n",
    "\n",
    "    def process_testing_data(self, folder_path, verbose=True):\n",
    "        \"\"\"\n",
    "        Process testing data with flat structure\n",
    "        \n",
    "        Args:\n",
    "            folder_path (str): Path to testing folder containing wav files\n",
    "            verbose (bool): Whether to print processing details\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame containing features for all audio files\n",
    "        \"\"\"\n",
    "        features_list = []\n",
    "        processed_files = 0\n",
    "        failed_files = 0\n",
    "        \n",
    "        # Check if folder exists\n",
    "        if not os.path.exists(folder_path):\n",
    "            raise ValueError(f\"Testing folder not found: {folder_path}\")\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing testing data from: {folder_path}\")\n",
    "            \n",
    "        # Get all wav files\n",
    "        audio_files = list(Path(folder_path).glob('*.wav'))\n",
    "        \n",
    "        if not audio_files:\n",
    "            raise ValueError(f\"No .wav files found in {folder_path}\")\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"Found {len(audio_files)} test files\")\n",
    "        \n",
    "        for audio_file in audio_files:\n",
    "            try:\n",
    "                features = self.process_audio(str(audio_file), 'unknown')\n",
    "                features_list.append(features)\n",
    "                processed_files += 1\n",
    "                if verbose and processed_files % 10 == 0:\n",
    "                    print(f\"Processed {processed_files} files...\")\n",
    "            except Exception as e:\n",
    "                failed_files += 1\n",
    "                print(f\"Error processing {audio_file}: {str(e)}\")\n",
    "                \n",
    "        if not features_list:\n",
    "            raise ValueError(f\"No files were successfully processed. Failed files: {failed_files}\")\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"\\nProcessing complete. Successfully processed {processed_files} files. Failed: {failed_files}\")\n",
    "            \n",
    "        df = pd.DataFrame(features_list)\n",
    "        \n",
    "        # Convert all columns to float except 'file_name' and 'instrument_type'\n",
    "        for col in df.columns:\n",
    "            if col != 'file_name' and col != 'instrument_type':\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "        return df\n",
    "\n",
    "    def validate_features(self, dataset):\n",
    "        \"\"\"\n",
    "        Validate features before scaling\n",
    "        \n",
    "        Args:\n",
    "            dataset (pandas.DataFrame): Dataset to validate\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (validated_dataset, feature_columns)\n",
    "        \"\"\"\n",
    "        # Remove any constant columns\n",
    "        feature_columns = [col for col in dataset.columns \n",
    "                         if col not in ['file_name', 'instrument_type']]\n",
    "        \n",
    "        # Check for and handle invalid values\n",
    "        for col in feature_columns:\n",
    "            # Replace inf values with NaN\n",
    "            dataset[col] = dataset[col].replace([np.inf, -np.inf], np.nan)\n",
    "            # Fill NaN values with column mean\n",
    "            mean_value = dataset[col].mean()\n",
    "            if pd.isna(mean_value):\n",
    "                print(f\"Warning: Column {col} contains all NaN values\")\n",
    "                dataset[col] = 0\n",
    "            else:\n",
    "                dataset[col] = dataset[col].fillna(mean_value)\n",
    "            \n",
    "        return dataset, feature_columns\n",
    "\n",
    "    def fit_scaler(self, dataset):\n",
    "        \"\"\"\n",
    "        Fit the scaler on the training data\n",
    "        \n",
    "        Args:\n",
    "            dataset (pandas.DataFrame): Training dataset\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: Validated dataset\n",
    "        \"\"\"\n",
    "        dataset, feature_columns = self.validate_features(dataset)\n",
    "        \n",
    "        if not feature_columns:\n",
    "            raise ValueError(\"No valid features found for scaling\")\n",
    "            \n",
    "        feature_data = dataset[feature_columns].astype(float)\n",
    "        self.scaler.fit(feature_data)\n",
    "        return dataset\n",
    "\n",
    "    def transform_data(self, dataset):\n",
    "        \"\"\"\n",
    "        Transform the data using the fitted scaler\n",
    "        \n",
    "        Args:\n",
    "            dataset (pandas.DataFrame): Dataset to transform\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: Transformed dataset\n",
    "        \"\"\"\n",
    "        dataset, feature_columns = self.validate_features(dataset)\n",
    "        \n",
    "        if not feature_columns:\n",
    "            raise ValueError(\"No valid features found for transformation\")\n",
    "            \n",
    "        feature_data = dataset[feature_columns].astype(float)\n",
    "        dataset[feature_columns] = self.scaler.transform(feature_data)\n",
    "        return dataset\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate usage\"\"\"\n",
    "    try:\n",
    "        # Define paths\n",
    "        base_path = os.path.join(os.getcwd(), \"/Users/payaldabas/Desktop/IRMAS-AI Sample\")\n",
    "        train_folder = os.path.join(base_path, \"IRMAS-TrainingData\")  # Contains instrument subfolders\n",
    "        test_folder = os.path.join(base_path, \"IRMAS-TestingData\")    # Contains wav files directly\n",
    "        \n",
    "        # Verify paths exist\n",
    "        for path in [base_path, train_folder, test_folder]:\n",
    "            if not os.path.exists(path):\n",
    "                print(f\"Creating directory: {path}\")\n",
    "                os.makedirs(path)\n",
    "        \n",
    "        # Initialize the preprocessor\n",
    "        preprocessor = MusicPreprocessor()\n",
    "        \n",
    "        # Process training data with instrument folders\n",
    "        print(\"\\nProcessing training data...\")\n",
    "        train_data = preprocessor.process_training_data(train_folder, verbose=True)\n",
    "        print(f\"Training data shape: {train_data.shape}\")\n",
    "        \n",
    "        # Process testing data with flat structure\n",
    "        print(\"\\nProcessing testing data...\")\n",
    "        test_data = preprocessor.process_testing_data(test_folder, verbose=True)\n",
    "        print(f\"Testing data shape: {test_data.shape}\")\n",
    "        \n",
    "        # Fit scaler on training data and transform both datasets\n",
    "        print(\"\\nNormalizing features...\")\n",
    "        train_data = preprocessor.fit_scaler(train_data)\n",
    "        train_data = preprocessor.transform_data(train_data)\n",
    "        test_data = preprocessor.transform_data(test_data)\n",
    "        \n",
    "        # Save processed datasets\n",
    "        train_data.to_csv(\"processed_train_data.csv\", index=False)\n",
    "        test_data.to_csv(\"processed_test_data.csv\", index=False)\n",
    "        \n",
    "        print(\"\\nDataset processing complete!\")\n",
    "        \n",
    "        # Display feature information\n",
    "        print(\"\\nFeature statistics (training data):\")\n",
    "        print(train_data.describe())\n",
    "        \n",
    "        # Display instrument distribution in training data\n",
    "        if 'instrument_type' in train_data.columns:\n",
    "            print(\"\\nInstrument distribution in training data:\")\n",
    "            print(train_data['instrument_type'].value_counts())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50289d-cba4-4e32-befa-997dddf847ef",
   "metadata": {},
   "source": [
    " ### Displayed Columns Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae85e694-df7e-4805-8db3-311a4ec219a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in processed training data:\n",
      "Index(['file_name', 'instrument_type', 'spectral_centroid_mean',\n",
      "       'spectral_bandwidth_mean', 'spectral_rolloff_mean', 'tempo',\n",
      "       'zero_crossing_rate', 'rmse_mean', 'mfcc_1_mean', 'mfcc_2_mean',\n",
      "       'mfcc_3_mean', 'mfcc_4_mean', 'mfcc_5_mean', 'mfcc_6_mean',\n",
      "       'mfcc_7_mean', 'mfcc_8_mean', 'mfcc_9_mean', 'mfcc_10_mean',\n",
      "       'mfcc_11_mean', 'mfcc_12_mean', 'mfcc_13_mean', 'chroma_1_mean',\n",
      "       'chroma_2_mean', 'chroma_3_mean', 'chroma_4_mean', 'chroma_5_mean',\n",
      "       'chroma_6_mean', 'chroma_7_mean', 'chroma_8_mean', 'chroma_9_mean',\n",
      "       'chroma_10_mean', 'chroma_11_mean', 'chroma_12_mean'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns in processed testing data:\n",
      "Index(['file_name', 'instrument_type', 'spectral_centroid_mean',\n",
      "       'spectral_bandwidth_mean', 'spectral_rolloff_mean', 'tempo',\n",
      "       'zero_crossing_rate', 'rmse_mean', 'mfcc_1_mean', 'mfcc_2_mean',\n",
      "       'mfcc_3_mean', 'mfcc_4_mean', 'mfcc_5_mean', 'mfcc_6_mean',\n",
      "       'mfcc_7_mean', 'mfcc_8_mean', 'mfcc_9_mean', 'mfcc_10_mean',\n",
      "       'mfcc_11_mean', 'mfcc_12_mean', 'mfcc_13_mean', 'chroma_1_mean',\n",
      "       'chroma_2_mean', 'chroma_3_mean', 'chroma_4_mean', 'chroma_5_mean',\n",
      "       'chroma_6_mean', 'chroma_7_mean', 'chroma_8_mean', 'chroma_9_mean',\n",
      "       'chroma_10_mean', 'chroma_11_mean', 'chroma_12_mean'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load and display columns of the processed training data\n",
    "train_data = pd.read_csv(\"processed_train_data.csv\")\n",
    "print(\"\\nColumns in processed training data:\")\n",
    "print(train_data.columns)\n",
    "\n",
    "# Load and display columns of the processed testing data\n",
    "test_data = pd.read_csv(\"processed_test_data.csv\")\n",
    "print(\"\\nColumns in processed testing data:\")\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44f85fa-4c68-44fe-bf3c-88e03e7c1f97",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e9d20c3-b25d-4499-80c8-db7397dee996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Fold 1\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.1603 - loss: 2.4475 - val_accuracy: 0.2525 - val_loss: 2.2784\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1919 - loss: 2.2984 - val_accuracy: 0.2323 - val_loss: 2.2616\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2304 - loss: 2.1054 - val_accuracy: 0.2323 - val_loss: 2.2339\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3068 - loss: 2.0073 - val_accuracy: 0.2020 - val_loss: 2.2431\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2640 - loss: 2.0071 - val_accuracy: 0.1414 - val_loss: 2.1919\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3259 - loss: 1.9212 - val_accuracy: 0.2020 - val_loss: 2.1780\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2845 - loss: 1.9011 - val_accuracy: 0.2626 - val_loss: 2.1692\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2096 - loss: 2.0739 - val_accuracy: 0.2222 - val_loss: 2.1333\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2488 - loss: 1.8896 - val_accuracy: 0.2727 - val_loss: 2.0633\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3221 - loss: 1.8383 - val_accuracy: 0.2525 - val_loss: 2.0678\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2437 - loss: 2.0002 - val_accuracy: 0.2323 - val_loss: 2.0949\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2882 - loss: 1.8720 - val_accuracy: 0.2424 - val_loss: 2.0577\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3072 - loss: 1.9135 - val_accuracy: 0.2525 - val_loss: 2.0412\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3340 - loss: 1.8581 - val_accuracy: 0.2121 - val_loss: 2.0242\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3852 - loss: 1.7964 - val_accuracy: 0.2525 - val_loss: 1.9758\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3340 - loss: 1.8231 - val_accuracy: 0.2525 - val_loss: 1.9487\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3122 - loss: 1.8190 - val_accuracy: 0.2929 - val_loss: 1.9169\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3438 - loss: 1.7427 - val_accuracy: 0.2828 - val_loss: 1.9066\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2922 - loss: 1.7688 - val_accuracy: 0.3232 - val_loss: 1.9500\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3692 - loss: 1.6686 - val_accuracy: 0.3131 - val_loss: 1.9457\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3468 - loss: 1.8353 - val_accuracy: 0.2828 - val_loss: 1.9247\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3152 - loss: 1.8193 - val_accuracy: 0.2929 - val_loss: 1.8697\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3328 - loss: 1.7459 - val_accuracy: 0.3636 - val_loss: 1.8489\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4143 - loss: 1.6198 - val_accuracy: 0.3434 - val_loss: 1.8690\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3829 - loss: 1.6744 - val_accuracy: 0.3333 - val_loss: 1.8612\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3646 - loss: 1.6971 - val_accuracy: 0.3131 - val_loss: 1.8555\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3968 - loss: 1.6787 - val_accuracy: 0.3333 - val_loss: 1.8217\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3652 - loss: 1.6383 - val_accuracy: 0.3131 - val_loss: 1.8806\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3997 - loss: 1.6513 - val_accuracy: 0.3333 - val_loss: 1.9205\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3939 - loss: 1.6791 - val_accuracy: 0.3232 - val_loss: 1.8500\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4053 - loss: 1.6113 - val_accuracy: 0.3232 - val_loss: 1.8969\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4191 - loss: 1.6335 - val_accuracy: 0.3333 - val_loss: 1.9356\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4099 - loss: 1.6757 - val_accuracy: 0.3535 - val_loss: 1.8962\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3601 - loss: 1.7258 - val_accuracy: 0.3131 - val_loss: 1.8841\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4021 - loss: 1.6047 - val_accuracy: 0.3535 - val_loss: 1.8448\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4113 - loss: 1.6309 - val_accuracy: 0.3636 - val_loss: 1.8259\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4703 - loss: 1.4833 - val_accuracy: 0.3636 - val_loss: 1.8170\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4864 - loss: 1.4063 - val_accuracy: 0.3636 - val_loss: 1.8346\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4269 - loss: 1.5193 - val_accuracy: 0.3737 - val_loss: 1.8241\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5150 - loss: 1.4290 - val_accuracy: 0.4545 - val_loss: 1.8504\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4973 - loss: 1.3633 - val_accuracy: 0.4040 - val_loss: 1.8764\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4258 - loss: 1.5904 - val_accuracy: 0.3333 - val_loss: 1.9112\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4149 - loss: 1.5169 - val_accuracy: 0.4040 - val_loss: 1.8433\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4290 - loss: 1.5333 - val_accuracy: 0.3434 - val_loss: 1.8743\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4408 - loss: 1.5381 - val_accuracy: 0.3434 - val_loss: 1.9539\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5088 - loss: 1.3857 - val_accuracy: 0.3131 - val_loss: 1.9065\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4500 - loss: 1.4500 - val_accuracy: 0.3535 - val_loss: 1.9266\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5158 - loss: 1.3454 - val_accuracy: 0.3939 - val_loss: 1.8665\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5229 - loss: 1.3602 - val_accuracy: 0.3838 - val_loss: 1.8708\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5353 - loss: 1.3261 - val_accuracy: 0.3636 - val_loss: 1.9545\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4080 - loss: 1.8836 \n",
      "\n",
      "Processing Fold 2\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.0989 - loss: 2.6771 - val_accuracy: 0.1414 - val_loss: 2.2857\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1821 - loss: 2.2439 - val_accuracy: 0.2020 - val_loss: 2.2654\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2131 - loss: 2.2150 - val_accuracy: 0.1515 - val_loss: 2.2499\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1994 - loss: 2.0684 - val_accuracy: 0.1515 - val_loss: 2.2288\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2362 - loss: 1.9859 - val_accuracy: 0.2020 - val_loss: 2.2269\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2987 - loss: 1.9769 - val_accuracy: 0.1717 - val_loss: 2.2170\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2902 - loss: 1.9933 - val_accuracy: 0.2323 - val_loss: 2.1702\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3134 - loss: 1.9114 - val_accuracy: 0.2626 - val_loss: 2.1561\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2602 - loss: 2.0200 - val_accuracy: 0.2626 - val_loss: 2.0841\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2681 - loss: 1.8903 - val_accuracy: 0.2424 - val_loss: 2.0959\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3251 - loss: 1.8871 - val_accuracy: 0.2323 - val_loss: 2.0821\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3103 - loss: 1.8946 - val_accuracy: 0.1717 - val_loss: 2.1115\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3267 - loss: 1.9244 - val_accuracy: 0.2020 - val_loss: 2.0834\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3474 - loss: 1.8574 - val_accuracy: 0.2525 - val_loss: 2.0727\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3699 - loss: 1.7908 - val_accuracy: 0.2424 - val_loss: 2.0552\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3355 - loss: 1.7775 - val_accuracy: 0.3030 - val_loss: 2.0657\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3431 - loss: 1.8046 - val_accuracy: 0.2626 - val_loss: 2.0752\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3974 - loss: 1.7924 - val_accuracy: 0.2929 - val_loss: 1.9784\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3445 - loss: 1.7986 - val_accuracy: 0.3535 - val_loss: 1.9295\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2904 - loss: 1.8425 - val_accuracy: 0.3232 - val_loss: 1.9264\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3651 - loss: 1.7456 - val_accuracy: 0.3131 - val_loss: 1.9383\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4071 - loss: 1.6437 - val_accuracy: 0.3434 - val_loss: 1.8519\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3278 - loss: 1.6950 - val_accuracy: 0.3030 - val_loss: 1.9199\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3632 - loss: 1.7568 - val_accuracy: 0.3030 - val_loss: 1.8688\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4106 - loss: 1.6120 - val_accuracy: 0.3333 - val_loss: 1.8973\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3663 - loss: 1.6811 - val_accuracy: 0.3131 - val_loss: 1.8767\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3575 - loss: 1.7810 - val_accuracy: 0.3737 - val_loss: 1.7657\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4121 - loss: 1.6117 - val_accuracy: 0.3232 - val_loss: 1.8304\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4191 - loss: 1.5755 - val_accuracy: 0.3030 - val_loss: 1.9491\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3747 - loss: 1.6739 - val_accuracy: 0.3232 - val_loss: 1.8858\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4370 - loss: 1.5914 - val_accuracy: 0.3030 - val_loss: 1.8320\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4476 - loss: 1.5770 - val_accuracy: 0.3131 - val_loss: 1.8368\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3833 - loss: 1.6164 - val_accuracy: 0.3535 - val_loss: 1.8561\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4561 - loss: 1.6233 - val_accuracy: 0.3434 - val_loss: 1.8335\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4264 - loss: 1.5720 - val_accuracy: 0.3636 - val_loss: 1.8489\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4335 - loss: 1.4993 - val_accuracy: 0.3030 - val_loss: 1.8661\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4836 - loss: 1.4476 - val_accuracy: 0.3535 - val_loss: 1.9087\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4655 - loss: 1.4827 - val_accuracy: 0.3535 - val_loss: 1.8756\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4509 - loss: 1.5455 - val_accuracy: 0.3131 - val_loss: 1.8507\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4784 - loss: 1.5257 - val_accuracy: 0.3434 - val_loss: 1.9200\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4289 - loss: 1.5065 - val_accuracy: 0.3939 - val_loss: 1.8522\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4372 - loss: 1.5091 - val_accuracy: 0.3939 - val_loss: 1.8290\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4706 - loss: 1.4720 - val_accuracy: 0.3434 - val_loss: 1.8660\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5239 - loss: 1.3477 - val_accuracy: 0.3737 - val_loss: 1.8086\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4421 - loss: 1.4505 - val_accuracy: 0.3535 - val_loss: 1.8588\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4607 - loss: 1.3881 - val_accuracy: 0.3636 - val_loss: 1.7874\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5250 - loss: 1.3686 - val_accuracy: 0.3737 - val_loss: 1.7936\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4734 - loss: 1.4035 - val_accuracy: 0.3636 - val_loss: 1.8674\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5015 - loss: 1.3732 - val_accuracy: 0.4141 - val_loss: 1.7866\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5198 - loss: 1.3253 - val_accuracy: 0.3838 - val_loss: 1.8126\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4171 - loss: 1.7283 \n",
      "\n",
      "Processing Fold 3\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.1095 - loss: 2.6235 - val_accuracy: 0.1010 - val_loss: 2.2878\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1336 - loss: 2.2261 - val_accuracy: 0.1616 - val_loss: 2.2751\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1659 - loss: 2.2580 - val_accuracy: 0.1919 - val_loss: 2.2642\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2423 - loss: 2.1162 - val_accuracy: 0.1616 - val_loss: 2.2294\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2541 - loss: 2.0339 - val_accuracy: 0.1717 - val_loss: 2.2210\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2416 - loss: 2.0098 - val_accuracy: 0.1515 - val_loss: 2.1703\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2279 - loss: 2.0764 - val_accuracy: 0.2525 - val_loss: 2.1304\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2982 - loss: 2.0201 - val_accuracy: 0.2020 - val_loss: 2.1491\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2182 - loss: 2.0168 - val_accuracy: 0.2525 - val_loss: 2.0504\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2849 - loss: 1.9076 - val_accuracy: 0.2828 - val_loss: 2.0165\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2830 - loss: 1.9853 - val_accuracy: 0.2121 - val_loss: 2.0311\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2834 - loss: 1.9229 - val_accuracy: 0.1515 - val_loss: 2.0530\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2636 - loss: 1.9520 - val_accuracy: 0.2323 - val_loss: 1.9504\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3051 - loss: 1.8637 - val_accuracy: 0.2626 - val_loss: 1.9134\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3561 - loss: 1.8197 - val_accuracy: 0.3333 - val_loss: 1.8600\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3514 - loss: 1.8729 - val_accuracy: 0.3535 - val_loss: 1.8605\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2774 - loss: 1.8305 - val_accuracy: 0.2929 - val_loss: 1.8182\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3256 - loss: 1.7754 - val_accuracy: 0.2828 - val_loss: 1.8744\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2839 - loss: 1.7792 - val_accuracy: 0.3131 - val_loss: 1.8111\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3099 - loss: 1.8506 - val_accuracy: 0.3636 - val_loss: 1.7822\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3717 - loss: 1.8151 - val_accuracy: 0.3131 - val_loss: 1.7652\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3424 - loss: 1.8056 - val_accuracy: 0.3434 - val_loss: 1.7501\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3265 - loss: 1.6786 - val_accuracy: 0.4141 - val_loss: 1.7160\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3408 - loss: 1.7798 - val_accuracy: 0.3838 - val_loss: 1.6938\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3873 - loss: 1.7078 - val_accuracy: 0.4242 - val_loss: 1.7615\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3839 - loss: 1.6751 - val_accuracy: 0.2828 - val_loss: 1.7615\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4367 - loss: 1.6266 - val_accuracy: 0.2727 - val_loss: 1.7331\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4042 - loss: 1.6932 - val_accuracy: 0.4444 - val_loss: 1.6869\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4487 - loss: 1.5548 - val_accuracy: 0.3535 - val_loss: 1.6933\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4125 - loss: 1.6088 - val_accuracy: 0.3434 - val_loss: 1.6915\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4030 - loss: 1.6536 - val_accuracy: 0.3636 - val_loss: 1.6219\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3934 - loss: 1.6405 - val_accuracy: 0.4343 - val_loss: 1.6856\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3988 - loss: 1.6158 - val_accuracy: 0.4242 - val_loss: 1.6078\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4570 - loss: 1.4907 - val_accuracy: 0.4343 - val_loss: 1.6421\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4255 - loss: 1.5581 - val_accuracy: 0.4040 - val_loss: 1.6324\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4127 - loss: 1.5672 - val_accuracy: 0.4646 - val_loss: 1.6571\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4540 - loss: 1.4962 - val_accuracy: 0.3535 - val_loss: 1.7747\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4192 - loss: 1.4996 - val_accuracy: 0.4444 - val_loss: 1.5975\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4314 - loss: 1.4991 - val_accuracy: 0.4141 - val_loss: 1.6454\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3943 - loss: 1.5289 - val_accuracy: 0.3939 - val_loss: 1.7008\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4027 - loss: 1.6161 - val_accuracy: 0.3939 - val_loss: 1.6736\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5132 - loss: 1.4326 - val_accuracy: 0.3939 - val_loss: 1.6194\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4653 - loss: 1.4521 - val_accuracy: 0.4848 - val_loss: 1.5634\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4509 - loss: 1.4998 - val_accuracy: 0.4343 - val_loss: 1.5910\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4448 - loss: 1.4632 - val_accuracy: 0.3939 - val_loss: 1.5810\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4729 - loss: 1.3899 - val_accuracy: 0.3535 - val_loss: 1.6851\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4949 - loss: 1.3334 - val_accuracy: 0.5051 - val_loss: 1.5600\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5278 - loss: 1.3050 - val_accuracy: 0.4040 - val_loss: 1.7124\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5049 - loss: 1.4101 - val_accuracy: 0.4646 - val_loss: 1.5444\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4460 - loss: 1.3912 - val_accuracy: 0.4646 - val_loss: 1.6411\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4973 - loss: 1.5605 \n",
      "\n",
      "Processing Fold 4\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.1336 - loss: 2.6505 - val_accuracy: 0.2143 - val_loss: 2.2670\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1928 - loss: 2.1985 - val_accuracy: 0.2245 - val_loss: 2.2667\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2254 - loss: 2.1579 - val_accuracy: 0.2041 - val_loss: 2.2061\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2356 - loss: 1.9919 - val_accuracy: 0.2143 - val_loss: 2.1937\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2532 - loss: 1.9716 - val_accuracy: 0.2041 - val_loss: 2.1542\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2754 - loss: 1.9442 - val_accuracy: 0.1429 - val_loss: 2.1589\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2422 - loss: 1.9786 - val_accuracy: 0.2449 - val_loss: 2.1229\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2913 - loss: 1.9738 - val_accuracy: 0.2143 - val_loss: 2.1215\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2982 - loss: 1.9654 - val_accuracy: 0.2041 - val_loss: 2.0759\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2961 - loss: 1.9028 - val_accuracy: 0.2347 - val_loss: 2.0688\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2768 - loss: 1.9454 - val_accuracy: 0.2449 - val_loss: 2.0212\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3549 - loss: 1.8289 - val_accuracy: 0.2653 - val_loss: 1.9750\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3040 - loss: 1.9032 - val_accuracy: 0.2551 - val_loss: 1.9565\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3002 - loss: 1.9172 - val_accuracy: 0.3265 - val_loss: 1.9271\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3222 - loss: 1.8056 - val_accuracy: 0.3265 - val_loss: 1.9132\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3510 - loss: 1.8086 - val_accuracy: 0.2551 - val_loss: 1.9388\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3260 - loss: 1.8646 - val_accuracy: 0.2551 - val_loss: 1.9377\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2725 - loss: 1.8741 - val_accuracy: 0.2755 - val_loss: 1.8736\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3002 - loss: 1.8447 - val_accuracy: 0.2755 - val_loss: 1.8397\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3434 - loss: 1.7571 - val_accuracy: 0.2755 - val_loss: 1.8538\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3540 - loss: 1.7121 - val_accuracy: 0.3367 - val_loss: 1.7715\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3741 - loss: 1.6728 - val_accuracy: 0.3163 - val_loss: 1.7699\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3400 - loss: 1.7751 - val_accuracy: 0.3163 - val_loss: 1.7937\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2979 - loss: 1.7930 - val_accuracy: 0.2857 - val_loss: 1.8712\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4055 - loss: 1.7140 - val_accuracy: 0.2857 - val_loss: 1.8564\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3929 - loss: 1.7379 - val_accuracy: 0.3163 - val_loss: 1.8530\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3517 - loss: 1.7796 - val_accuracy: 0.3469 - val_loss: 1.7576\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3712 - loss: 1.6860 - val_accuracy: 0.3469 - val_loss: 1.7124\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3629 - loss: 1.6826 - val_accuracy: 0.4082 - val_loss: 1.6959\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4271 - loss: 1.6026 - val_accuracy: 0.3469 - val_loss: 1.7755\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3579 - loss: 1.6738 - val_accuracy: 0.3061 - val_loss: 1.7549\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3826 - loss: 1.6450 - val_accuracy: 0.3163 - val_loss: 1.7299\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3811 - loss: 1.7087 - val_accuracy: 0.3367 - val_loss: 1.6964\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4041 - loss: 1.6398 - val_accuracy: 0.3776 - val_loss: 1.6915\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4531 - loss: 1.5091 - val_accuracy: 0.3163 - val_loss: 1.7663\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4482 - loss: 1.4810 - val_accuracy: 0.3673 - val_loss: 1.7358\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4469 - loss: 1.5495 - val_accuracy: 0.2959 - val_loss: 1.7721\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4382 - loss: 1.5375 - val_accuracy: 0.3367 - val_loss: 1.7096\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4222 - loss: 1.5956 - val_accuracy: 0.3776 - val_loss: 1.7359\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4135 - loss: 1.5347 - val_accuracy: 0.3367 - val_loss: 1.7868\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4225 - loss: 1.4691 - val_accuracy: 0.3265 - val_loss: 1.7159\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4271 - loss: 1.4934 - val_accuracy: 0.3776 - val_loss: 1.7519\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4593 - loss: 1.4840 - val_accuracy: 0.3571 - val_loss: 1.6514\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4244 - loss: 1.4883 - val_accuracy: 0.3265 - val_loss: 1.7362\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4996 - loss: 1.4164 - val_accuracy: 0.3061 - val_loss: 1.7751\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4628 - loss: 1.4633 - val_accuracy: 0.3469 - val_loss: 1.6725\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4630 - loss: 1.4810 - val_accuracy: 0.3367 - val_loss: 1.7292\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4200 - loss: 1.5100 - val_accuracy: 0.4082 - val_loss: 1.7074\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5161 - loss: 1.4113 - val_accuracy: 0.3776 - val_loss: 1.7612\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4716 - loss: 1.4493 - val_accuracy: 0.3469 - val_loss: 1.7356\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3346 - loss: 1.7674 \n",
      "\n",
      "Processing Fold 5\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.0820 - loss: 2.5995 - val_accuracy: 0.1429 - val_loss: 2.2900\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2244 - loss: 2.1969 - val_accuracy: 0.1531 - val_loss: 2.2623\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2474 - loss: 2.0998 - val_accuracy: 0.1429 - val_loss: 2.2577\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2712 - loss: 2.0551 - val_accuracy: 0.1531 - val_loss: 2.2262\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2500 - loss: 1.9912 - val_accuracy: 0.2041 - val_loss: 2.2119\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3110 - loss: 1.9320 - val_accuracy: 0.1837 - val_loss: 2.2135\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2838 - loss: 1.9352 - val_accuracy: 0.2041 - val_loss: 2.1369\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3082 - loss: 1.9538 - val_accuracy: 0.1837 - val_loss: 2.1560\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2503 - loss: 2.0292 - val_accuracy: 0.2143 - val_loss: 2.1236\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2981 - loss: 1.9637 - val_accuracy: 0.1633 - val_loss: 2.1043\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3161 - loss: 1.9274 - val_accuracy: 0.2041 - val_loss: 2.0614\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2973 - loss: 1.8876 - val_accuracy: 0.2449 - val_loss: 1.9878\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2930 - loss: 1.8815 - val_accuracy: 0.2041 - val_loss: 2.0497\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3340 - loss: 1.8051 - val_accuracy: 0.3163 - val_loss: 1.9620\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3189 - loss: 1.7977 - val_accuracy: 0.2653 - val_loss: 1.9404\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3802 - loss: 1.7559 - val_accuracy: 0.2755 - val_loss: 1.9078\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3288 - loss: 1.8372 - val_accuracy: 0.2857 - val_loss: 1.8765\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3531 - loss: 1.7829 - val_accuracy: 0.2755 - val_loss: 1.9225\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3332 - loss: 1.7578 - val_accuracy: 0.3163 - val_loss: 1.8762\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3567 - loss: 1.7237 - val_accuracy: 0.2959 - val_loss: 1.8656\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3233 - loss: 1.7772 - val_accuracy: 0.3061 - val_loss: 1.8357\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3444 - loss: 1.7209 - val_accuracy: 0.3980 - val_loss: 1.8006\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3831 - loss: 1.6808 - val_accuracy: 0.4082 - val_loss: 1.7187\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3723 - loss: 1.7160 - val_accuracy: 0.3776 - val_loss: 1.7369\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3374 - loss: 1.6655 - val_accuracy: 0.3571 - val_loss: 1.7190\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3527 - loss: 1.6347 - val_accuracy: 0.3878 - val_loss: 1.6775\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3712 - loss: 1.6101 - val_accuracy: 0.3776 - val_loss: 1.7342\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4215 - loss: 1.6391 - val_accuracy: 0.4082 - val_loss: 1.7141\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4038 - loss: 1.6131 - val_accuracy: 0.3673 - val_loss: 1.7278\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4057 - loss: 1.6427 - val_accuracy: 0.3673 - val_loss: 1.7935\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3853 - loss: 1.6085 - val_accuracy: 0.3776 - val_loss: 1.6942\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4111 - loss: 1.5793 - val_accuracy: 0.3673 - val_loss: 1.7142\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4069 - loss: 1.6068 - val_accuracy: 0.4490 - val_loss: 1.6192\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4334 - loss: 1.5426 - val_accuracy: 0.3980 - val_loss: 1.6789\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4367 - loss: 1.5204 - val_accuracy: 0.3980 - val_loss: 1.7210\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4417 - loss: 1.4886 - val_accuracy: 0.4286 - val_loss: 1.6375\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4469 - loss: 1.5410 - val_accuracy: 0.4286 - val_loss: 1.6975\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4299 - loss: 1.5379 - val_accuracy: 0.3980 - val_loss: 1.6250\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4265 - loss: 1.4922 - val_accuracy: 0.3776 - val_loss: 1.6992\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4580 - loss: 1.4856 - val_accuracy: 0.4490 - val_loss: 1.5876\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4839 - loss: 1.3566 - val_accuracy: 0.3878 - val_loss: 1.6395\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4734 - loss: 1.4466 - val_accuracy: 0.3469 - val_loss: 1.7339\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4856 - loss: 1.3714 - val_accuracy: 0.4286 - val_loss: 1.6461\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4484 - loss: 1.4467 - val_accuracy: 0.3878 - val_loss: 1.6689\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5231 - loss: 1.3578 - val_accuracy: 0.3980 - val_loss: 1.6232\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5063 - loss: 1.3753 - val_accuracy: 0.4286 - val_loss: 1.6079\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5227 - loss: 1.4068 - val_accuracy: 0.4388 - val_loss: 1.7184\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4308 - loss: 1.5462 - val_accuracy: 0.3980 - val_loss: 1.6726\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5211 - loss: 1.2794 - val_accuracy: 0.3776 - val_loss: 1.6216\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5216 - loss: 1.3791 - val_accuracy: 0.3980 - val_loss: 1.7072\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4154 - loss: 1.6319 \n",
      "\n",
      "Cross-Validation Accuracy: 0.3914 ± 0.0405\n",
      "Epoch 1/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1180 - loss: 2.5381\n",
      "Epoch 2/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1733 - loss: 2.1902\n",
      "Epoch 3/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2403 - loss: 2.0938\n",
      "Epoch 4/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2325 - loss: 2.0891\n",
      "Epoch 5/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2993 - loss: 2.0137\n",
      "Epoch 6/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3057 - loss: 1.9485\n",
      "Epoch 7/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2403 - loss: 2.0686\n",
      "Epoch 8/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2710 - loss: 1.9237\n",
      "Epoch 9/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2844 - loss: 1.9741\n",
      "Epoch 10/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2913 - loss: 1.8637\n",
      "Epoch 11/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2519 - loss: 2.0450\n",
      "Epoch 12/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2621 - loss: 1.9421\n",
      "Epoch 13/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2565 - loss: 1.8986\n",
      "Epoch 14/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3420 - loss: 1.9174\n",
      "Epoch 15/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3085 - loss: 1.9182\n",
      "Epoch 16/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3053 - loss: 1.8527\n",
      "Epoch 17/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3451 - loss: 1.8029\n",
      "Epoch 18/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3406 - loss: 1.8665\n",
      "Epoch 19/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3747 - loss: 1.7397\n",
      "Epoch 20/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3200 - loss: 1.8334\n",
      "Epoch 21/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3242 - loss: 1.8393\n",
      "Epoch 22/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3701 - loss: 1.7537\n",
      "Epoch 23/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3979 - loss: 1.7232\n",
      "Epoch 24/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3643 - loss: 1.7256\n",
      "Epoch 25/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3627 - loss: 1.6639\n",
      "Epoch 26/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3394 - loss: 1.7673\n",
      "Epoch 27/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3899 - loss: 1.7237\n",
      "Epoch 28/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3829 - loss: 1.6792\n",
      "Epoch 29/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4019 - loss: 1.6808\n",
      "Epoch 30/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4102 - loss: 1.6212\n",
      "Epoch 31/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3599 - loss: 1.6459\n",
      "Epoch 32/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3999 - loss: 1.6135\n",
      "Epoch 33/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4424 - loss: 1.5829\n",
      "Epoch 34/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3796 - loss: 1.5877\n",
      "Epoch 35/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4283 - loss: 1.5804\n",
      "Epoch 36/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4126 - loss: 1.6030\n",
      "Epoch 37/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4217 - loss: 1.5922\n",
      "Epoch 38/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4288 - loss: 1.5222\n",
      "Epoch 39/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4470 - loss: 1.5164\n",
      "Epoch 40/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4262 - loss: 1.5245\n",
      "Epoch 41/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4680 - loss: 1.4278\n",
      "Epoch 42/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4784 - loss: 1.4302\n",
      "Epoch 43/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4040 - loss: 1.5220\n",
      "Epoch 44/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4737 - loss: 1.4508\n",
      "Epoch 45/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5017 - loss: 1.3822\n",
      "Epoch 46/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4719 - loss: 1.4166\n",
      "Epoch 47/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4891 - loss: 1.3541\n",
      "Epoch 48/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5102 - loss: 1.3253\n",
      "Epoch 49/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4624 - loss: 1.4433\n",
      "Epoch 50/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5035 - loss: 1.3220\n",
      "\n",
      "Evaluating on Training Data...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " acoustic guitar       0.61      0.84      0.71        49\n",
      "           cello       0.66      0.63      0.65        49\n",
      "        clarinet       0.83      0.71      0.77        49\n",
      "electric guitar        0.62      0.49      0.55        49\n",
      "          flute        0.65      0.65      0.65        49\n",
      "           organ       0.51      0.80      0.62        49\n",
      "           piano       0.76      0.42      0.54        52\n",
      "       saxophone       0.49      0.49      0.49        49\n",
      "        trumpet        0.59      0.41      0.48        49\n",
      "          violin       0.69      0.86      0.76        49\n",
      "\n",
      "        accuracy                           0.63       493\n",
      "       macro avg       0.64      0.63      0.62       493\n",
      "    weighted avg       0.64      0.63      0.62       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on Test Data...\n",
      "Test Loss: 1.2000\n",
      "Test Accuracy: 0.6542\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\n",
      "Test Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 10, does not match size of target_names, 11. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 215\u001b[0m\n\u001b[1;32m    211\u001b[0m     classifier\u001b[38;5;241m.\u001b[39mevaluate_test(X_test, y_test)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[42], line 211\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating on Training Data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m classifier\u001b[38;5;241m.\u001b[39mevaluate(X_train, y_train)\n\u001b[0;32m--> 211\u001b[0m classifier\u001b[38;5;241m.\u001b[39mevaluate_test(X_test, y_test)\n",
      "Cell \u001b[0;32mIn[42], line 175\u001b[0m, in \u001b[0;36mInstrumentClassifier.evaluate_test\u001b[0;34m(self, X_test, y_test)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Generate a classification report\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\n\u001b[1;32m    176\u001b[0m     y_test_encoded,\n\u001b[1;32m    177\u001b[0m     y_pred_classes,\n\u001b[1;32m    178\u001b[0m     target_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_encoder\u001b[38;5;241m.\u001b[39mclasses_,\n\u001b[1;32m    179\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Handle cases with zero predictions\u001b[39;00m\n\u001b[1;32m    180\u001b[0m ))\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Confusion matrix\u001b[39;00m\n\u001b[1;32m    183\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test_encoded, y_pred_classes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2626\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2620\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2621\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2622\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2623\u001b[0m             )\n\u001b[1;32m   2624\u001b[0m         )\n\u001b[1;32m   2625\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2626\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2627\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2628\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2629\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2630\u001b[0m         )\n\u001b[1;32m   2631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2632\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 10, does not match size of target_names, 11. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class InstrumentClassifier:\n",
    "    def __init__(self, learning_rate=0.001, epochs=50, batch_size=16):\n",
    "        self.model = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self, X, y=None, training=True):\n",
    "        # Clear memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        # Encode labels if training\n",
    "        if training and y is not None:\n",
    "            y = self.label_encoder.fit_transform(y)\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        # Reshape data for LSTM\n",
    "        X = np.float32(X.astype(float))\n",
    "        X = np.expand_dims(X, axis=2)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def build_model(self, input_shape, num_classes):\n",
    "        # Clear previous models\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        model = Sequential([\n",
    "            LSTM(128, input_shape=input_shape,\n",
    "                 return_sequences=True,\n",
    "                 recurrent_dropout=0.2),\n",
    "            BatchNormalization(),\n",
    "\n",
    "            LSTM(64, recurrent_dropout=0.2),\n",
    "            BatchNormalization(),\n",
    "\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=self.learning_rate),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def cross_validate(self, X, y):\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        X, _ = self.prepare_data(X)\n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        num_classes = len(self.label_encoder.classes_)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_encoded), 1):\n",
    "            print(f\"\\nProcessing Fold {fold}\")\n",
    "\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train = to_categorical(y_encoded[train_idx], num_classes)\n",
    "            y_val = to_categorical(y_encoded[val_idx], num_classes)\n",
    "\n",
    "            model = self.build_model(input_shape=(X.shape[1], 1), num_classes=num_classes)\n",
    "\n",
    "            try:\n",
    "                history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=self.epochs,\n",
    "                    batch_size=self.batch_size,\n",
    "                    verbose=1\n",
    "                )\n",
    "\n",
    "                _, accuracy = model.evaluate(X_val, y_val)\n",
    "                cv_scores.append(accuracy)\n",
    "\n",
    "                del model\n",
    "                gc.collect()\n",
    "                tf.keras.backend.clear_session()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in fold {fold}: {e}\")\n",
    "\n",
    "        print(f\"\\nCross-Validation Accuracy: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
    "\n",
    "    def train(self, X, y):\n",
    "        X, y = self.prepare_data(X, y)\n",
    "        num_classes = len(self.label_encoder.classes_)\n",
    "\n",
    "        self.model = self.build_model(input_shape=(X.shape[1], 1), num_classes=num_classes)\n",
    "\n",
    "        self.model.fit(\n",
    "            X, y,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        X, _ = self.prepare_data(X, training=False)\n",
    "        y_encoded = self.label_encoder.transform(y)\n",
    "\n",
    "        y_pred = self.model.predict(X)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(\n",
    "            y_encoded,\n",
    "            y_pred_classes,\n",
    "            target_names=self.label_encoder.classes_\n",
    "        ))\n",
    "\n",
    "        cm = confusion_matrix(y_encoded, y_pred_classes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=self.label_encoder.classes_,\n",
    "                    yticklabels=self.label_encoder.classes_)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate_test(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the model on testing data, ensuring consistent class alignment.\n",
    "        \"\"\"\n",
    "        # Preprocess the test data\n",
    "        X_test, _ = self.prepare_data(X_test, training=False)\n",
    "\n",
    "        # Update label encoder's classes to include all unique labels from training and test sets\n",
    "        all_classes = np.union1d(self.label_encoder.classes_, np.unique(y_test))\n",
    "        self.label_encoder.classes_ = all_classes\n",
    "\n",
    "        # Encode the test labels\n",
    "        y_test_encoded = self.label_encoder.transform(y_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        print(\"\\nEvaluating on Test Data...\")\n",
    "        \n",
    "        # Uncomment the following line for real evaluation\n",
    "        test_loss, test_accuracy = self.model.evaluate(X_test, to_categorical(y_test_encoded), verbose=1)\n",
    "        \n",
    "        print(f\"Test Loss: {test_loss:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "        # Predict classes\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Generate a classification report\n",
    "        print(\"\\nTest Classification Report:\")\n",
    "        print(classification_report(\n",
    "            y_test_encoded,\n",
    "            y_pred_classes,\n",
    "            target_names=self.label_encoder.classes_,\n",
    "            zero_division=0  # Handle cases with zero predictions\n",
    "        ))\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test_encoded, y_pred_classes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=self.label_encoder.classes_,\n",
    "                    yticklabels=self.label_encoder.classes_)\n",
    "        plt.title('Test Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_data = pd.read_csv('processed_train_data.csv')\n",
    "    test_data = pd.read_csv('processed_test_data.csv')\n",
    "\n",
    "    X_train = train_data.drop(['file_name', 'instrument_type'], axis=1)\n",
    "    y_train = train_data['instrument_type']\n",
    "\n",
    "    X_test = test_data.drop(['file_name', 'instrument_type'], axis=1)\n",
    "    y_test = test_data['instrument_type']\n",
    "\n",
    "    classifier = InstrumentClassifier()\n",
    "\n",
    "    classifier.cross_validate(X_train, y_train)\n",
    "\n",
    "    classifier.train(X_train, y_train)\n",
    "\n",
    "    print(\"\\nEvaluating on Training Data...\")\n",
    "    classifier.evaluate(X_train, y_train)\n",
    "\n",
    "    classifier.evaluate_test(X_test, y_test)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2a432-5a22-4f6b-9ed9-2fcdf2b847c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "985f08cb-2562-456a-9eff-04e149cc7079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">991</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">247</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">243</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30720</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,864,576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_layer_1 (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m991\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m5,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_layer_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m247\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_layer_2 (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m243\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,311,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_layer_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30720\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc_layer_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m7,864,576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc_layer_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,214,723</span> (35.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,214,723\u001b[0m (35.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,214,723</span> (35.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,214,723\u001b[0m (35.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define dropout probability\n",
    "drop_out_prob = 0.25\n",
    "\n",
    "def build_keras_cnn(feature_length, num_classes=3):\n",
    "    \"\"\"\n",
    "    Builds a 1D Convolutional Neural Network for audio feature classification.\n",
    "\n",
    "    Parameters:\n",
    "    - feature_length: int, length of the input feature vector for each audio sample.\n",
    "    - num_classes: int, the number of output classes for classification.\n",
    "\n",
    "    Returns:\n",
    "    - model: tf.keras.Model, compiled CNN model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input layer for 1D audio data\n",
    "    input_layer = Input(shape=(feature_length, 1))\n",
    "\n",
    "    # First Convolutional and Max Pooling layers\n",
    "    conv_layer_1 = Conv1D(512, 10, activation='relu', kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(), name='conv_layer_1')(input_layer)\n",
    "    pool_layer_1 = MaxPooling1D(pool_size=4, name='pool_layer_1')(conv_layer_1)\n",
    "\n",
    "    # Second Convolutional and Max Pooling layers\n",
    "    conv_layer_2 = Conv1D(512, 5, activation='relu', kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(), name='conv_layer_2')(pool_layer_1)\n",
    "    pool_layer_2 = MaxPooling1D(pool_size=4, name='pool_layer_2')(conv_layer_2)\n",
    "\n",
    "    # Flattening layer to feed into Dense layers\n",
    "    flat_layer = Flatten()(pool_layer_2)\n",
    "\n",
    "    # First Fully Connected (Dense) layer with dropout\n",
    "    fc_layer_1 = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(), name='fc_layer_1')(flat_layer)\n",
    "    drop_layer_1 = Dropout(drop_out_prob)(fc_layer_1)\n",
    "\n",
    "    # Second Fully Connected layer with dropout\n",
    "    fc_layer_2 = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(), name='fc_layer_2')(drop_layer_1)\n",
    "    drop_layer_2 = Dropout(drop_out_prob)(fc_layer_2)\n",
    "\n",
    "    # Output layer with softmax for multi-class classification\n",
    "    output_layer = Dense(num_classes, activation='softmax', name='output')(drop_layer_2)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# Assuming feature_length is known and num_classes is the number of instrument types you are classifying\n",
    "feature_length = 1000  # Replace with your actual feature length\n",
    "num_classes = 3  # Replace with your actual number of classes\n",
    "model = build_keras_cnn(feature_length, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6472d792-04d7-45c9-a121-c8999a5582a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "Training samples: 493\n",
      "Training the model...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1545 - loss: 21.6488\n",
      "Epoch 2/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0860 - loss: 5.7441\n",
      "Epoch 3/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1252 - loss: 5.5568\n",
      "Epoch 4/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0985 - loss: 5.3945\n",
      "Epoch 5/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1066 - loss: 5.2524\n",
      "Epoch 6/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1398 - loss: 5.0710\n",
      "Epoch 7/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1250 - loss: 4.9339\n",
      "Epoch 8/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1304 - loss: 4.8041\n",
      "Epoch 9/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1129 - loss: 4.6673\n",
      "Epoch 10/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1571 - loss: 4.5159\n",
      "Epoch 11/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1815 - loss: 4.3266\n",
      "Epoch 12/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1523 - loss: 4.2093\n",
      "Epoch 13/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2124 - loss: 4.0343\n",
      "Epoch 14/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1993 - loss: 4.0039\n",
      "Epoch 15/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1886 - loss: 3.8857\n",
      "Epoch 16/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1992 - loss: 3.8417\n",
      "Epoch 17/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2279 - loss: 3.6940\n",
      "Epoch 18/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2359 - loss: 3.6215\n",
      "Epoch 19/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2442 - loss: 3.5796\n",
      "Epoch 20/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2403 - loss: 3.4353\n",
      "Epoch 21/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2761 - loss: 3.3167\n",
      "Epoch 22/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2297 - loss: 3.3942\n",
      "Epoch 23/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2726 - loss: 3.2298\n",
      "Epoch 24/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2375 - loss: 3.2490\n",
      "Epoch 25/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2786 - loss: 3.1424\n",
      "Epoch 26/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2274 - loss: 3.1576\n",
      "Epoch 27/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2768 - loss: 3.0581\n",
      "Epoch 28/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3295 - loss: 2.9524\n",
      "Epoch 29/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3106 - loss: 2.9521\n",
      "Epoch 30/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3234 - loss: 2.9131\n",
      "Epoch 31/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3633 - loss: 2.7329\n",
      "Epoch 32/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3103 - loss: 2.8723\n",
      "Epoch 33/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3618 - loss: 2.6210\n",
      "Epoch 34/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3599 - loss: 2.7003\n",
      "Epoch 35/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3517 - loss: 2.6103\n",
      "Epoch 36/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4006 - loss: 2.4974\n",
      "Epoch 37/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4012 - loss: 2.5910\n",
      "Epoch 38/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3380 - loss: 2.5234\n",
      "Epoch 39/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4085 - loss: 2.4558\n",
      "Epoch 40/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4123 - loss: 2.4335\n",
      "Epoch 41/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3594 - loss: 2.4278\n",
      "Epoch 42/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4374 - loss: 2.4103\n",
      "Epoch 43/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4739 - loss: 2.2606\n",
      "Epoch 44/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3929 - loss: 2.3422\n",
      "Epoch 45/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4213 - loss: 2.2997\n",
      "Epoch 46/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4634 - loss: 2.2254\n",
      "Epoch 47/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5074 - loss: 2.2210\n",
      "Epoch 48/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4878 - loss: 2.1877\n",
      "Epoch 49/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4619 - loss: 2.2043\n",
      "Epoch 50/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4650 - loss: 2.2177\n",
      "Training Accuracy: 67.34%\n",
      "Processing testing data...\n",
      "Testing samples: 300\n",
      "Evaluating test performance...\n",
      "Test Accuracy: 54.64%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import random\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(file_path, n_mfcc=40, max_pad_len=44):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, duration=5)  # Load audio file\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "        # Pad or truncate MFCC to max_pad_len\n",
    "        if mfcc.shape[1] < max_pad_len:\n",
    "            pad_width = max_pad_len - mfcc.shape[1]\n",
    "            mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mfcc = mfcc[:, :max_pad_len]\n",
    "        return mfcc\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Preprocess dataset\n",
    "def preprocess_data(data_path, n_mfcc, max_pad_len, is_test=False):\n",
    "    \"\"\"\n",
    "    Preprocess audio data.\n",
    "    Args:\n",
    "    - data_path: Path to the dataset.\n",
    "    - n_mfcc: Number of MFCC features to extract.\n",
    "    - max_pad_len: Maximum padding length for audio data.\n",
    "    - is_test: Set to True if the data_path is for testing, where files are directly in the directory.\n",
    "\n",
    "    Returns:\n",
    "    - X: Feature matrix.\n",
    "    - y: Labels (empty if is_test=True).\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    if is_test:\n",
    "        # Process audio files directly in the given directory\n",
    "        for file in os.listdir(data_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(data_path, file)\n",
    "                try:\n",
    "                    mfccs = extract_features(file_path, n_mfcc, max_pad_len)\n",
    "                    X.append(mfccs)\n",
    "                    y.append(file)  # Append filename for consistency; this will be empty in tests\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "    else:\n",
    "        # Process audio files within subfolders\n",
    "        for label in os.listdir(data_path):\n",
    "            label_path = os.path.join(data_path, label)\n",
    "            if os.path.isdir(label_path):\n",
    "                for file in os.listdir(label_path):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(label_path, file)\n",
    "                        try:\n",
    "                            mfccs = extract_features(file_path, n_mfcc, max_pad_len)\n",
    "                            X.append(mfccs)\n",
    "                            y.append(label)  # Use subfolder name as the label\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing {file_path}: {e}\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# CNN model\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape,\n",
    "                     kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    train_path = \"/Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TrainingData\"\n",
    "    test_path = \"/Users/payaldabas/Desktop/IRMAS-AI Sample/IRMAS-TestingData\"\n",
    "\n",
    "    n_mfcc = 40\n",
    "    max_pad_len = 44\n",
    "\n",
    "    # Preprocess training data\n",
    "    print(\"Processing training data...\")\n",
    "    X_train, y_train = preprocess_data(train_path, n_mfcc, max_pad_len)\n",
    "    if len(X_train) == 0 or len(y_train) == 0:\n",
    "        raise ValueError(\"Training data could not be loaded. Please check the directory and files.\")\n",
    "    print(f\"Training samples: {X_train.shape[0]}\")\n",
    "\n",
    "    # Encode labels\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    y_train = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "    # Reshape training data\n",
    "    X_train = X_train[..., np.newaxis]  # Add channel dimension for CNN\n",
    "\n",
    "    # Build model\n",
    "    input_shape = X_train.shape[1:]  # Infer from data\n",
    "    num_classes = len(label_binarizer.classes_)\n",
    "    model = build_cnn_model(input_shape, num_classes)\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Training the model...\")\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate training performance\n",
    "    train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Preprocess test data\n",
    "    print(\"Processing testing data...\")\n",
    "    X_test, y_test = preprocess_data(test_path, n_mfcc, max_pad_len, is_test=True)\n",
    "    if len(X_test) == 0:\n",
    "        raise ValueError(\"Test data could not be loaded. Please check the directory and files.\")\n",
    "    print(f\"Testing samples: {len(X_test)}\")\n",
    "\n",
    "    # Reshape test data\n",
    "    X_test = X_test[..., np.newaxis]  # Add channel dimension for CNN\n",
    "\n",
    "    # Evaluate test performance\n",
    "    print(\"Evaluating test performance...\")\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, np.zeros((len(X_test), num_classes)), verbose=0)\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bbf785-1c65-4268-ba00-43c44e9e34bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
